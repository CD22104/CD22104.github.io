<!DOCTYPE html>
<html lang="en" color-mode="light">

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="CD22104" />
  <!-- Open Graph Description 简短摘要-->
  
  <!-- 用于搜索引擎的文章摘要 -->
  
  
  
  <title>
    
      【论文】Fair diffusion-Instructing Text-to-Image Generation Models on Fairness 
      
      
      |
    
     CD的博客
  </title>

  
    <link rel="apple-touch-icon" href="/images/favicon.png">
    <link rel="icon" href="/images/favicon.png">
  

  <!-- Raleway-Font -->
  <link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">

  <!-- hexo site css -->
  <link rel="stylesheet" href="/css/main.css" />
  <link rel="stylesheet" href="//at.alicdn.com/t/font_1886449_67xjft27j1l.css" />
  <!-- 代码块风格 -->
  

  <!-- jquery3.3.1 -->
  
    <script defer type="text/javascript" src="/plugins/jquery.min.js"></script>
  

  <!-- fancybox -->
  
    <link href="/plugins/jquery.fancybox.min.css" rel="stylesheet">
    <script defer type="text/javascript" src="/plugins/jquery.fancybox.min.js"></script>
  
  
<script src="/js/fancybox.js"></script>


  

  

  <script>
    var html = document.documentElement
    const colorMode = localStorage.getItem('color-mode')
    if (colorMode) {
      document.documentElement.setAttribute('color-mode', colorMode)
    }
  </script>
<meta name="generator" content="Hexo 7.2.0"></head>


  <body>
    <div id="app">
      <div class="header">
  <div class="avatar">
    <a href="/">
      <!-- 头像取消懒加载，添加no-lazy -->
      
        <img src="/images/avatar.png" alt="">
      
    </a>
    <div class="nickname"><a href="/">Oranges</a></div>
  </div>
  <div class="navbar">
    <ul>
      
        <li class="nav-item" data-path="/">
          <a href="/">Home</a>
        </li>
      
        <li class="nav-item" data-path="/archives/">
          <a href="/archives/">Archives</a>
        </li>
      
        <li class="nav-item" data-path="/tags/">
          <a href="/tags/">Tags</a>
        </li>
      
        <li class="nav-item" data-path="/friends/">
          <a href="/friends/">Friends</a>
        </li>
      
        <li class="nav-item" data-path="/about/">
          <a href="/about/">About</a>
        </li>
      
    </ul>
  </div>
</div>


<script src="/js/activeNav.js"></script>



      <div class="flex-container">
        <!-- 文章详情页，展示文章具体内容，url形式：https://yoursite/文章标题/ -->
<!-- 同时为「标签tag」，「朋友friend」，「分类categories」，「关于about」页面的承载页面，具体展示取决于page.type -->


  <!-- LaTex Display -->

  
    <script async type="text/javascript" src="/plugins/mathjax/tex-chtml.js"></script>
  
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    }
  </script>





  <!-- clipboard -->

  
    <script async type="text/javascript" src="/plugins/clipboard.min.js"></script>
  
  
<script src="/js/codeCopy.js"></script>







  

  

  

  
  <!-- 文章内容页 url形式：https://yoursite/文章标题/ -->
  <div class="container post-details" id="post-details">
    <div class="post-content">
      <div class="post-title">【论文】Fair diffusion-Instructing Text-to-Image Generation Models on Fairness</div>
      <div class="post-attach">
        <span class="post-pubtime">
          <i class="iconfont icon-updatetime mr-10" title="Update time"></i>
          2024-04-21 16:33:15
        </span>
        
      </div>
      <div class="markdown-body">
        <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><ul>
<li>提出了一种称为公平扩散的新策略，以在部署生成文本到图像模型后减弱偏见。<ul>
<li>基于人类指令的偏见向任何方向转移，从而产生任意比例，例如身份群体。不需要数据过滤或额外的培训</li>
</ul>
</li>
<li>代码：Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/ml-research/Fair-Diffusion">https://github.com/ml-research/Fair-Diffusion</a></li>
<li>效果：<a target="_blank" rel="noopener" href="https://huggingface.co/spaces/AIML-TUDA/FairDiffusionExplorer">https://huggingface.co/spaces/AIML-TUDA/FairDiffusionExplorer</a></li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>Stable Diffusion作为一种Diffusion Models是目前广泛使用的图像合成模型的变体，它基于文本输入生成逼真的高质量图像</li>
<li>我们的工作<ul>
<li>审核生成模型的当前<strong>偏差的来源</strong>: stable diffusion的底层大规模数据集，和他的预训练模块<ul>
<li>创建LAION-5B的子集：包含超过1.8M张图片，描绘了150多个职业，以接近目前的性别职业偏见</li>
</ul>
</li>
<li><strong>评估</strong>其缓解措施：data-processing, in-process approaches<ul>
<li>提出了Fair Diffusion：在生成模型的部署阶段缓解偏差，利用一个（文本）界面来指导模型从而实现公平</li>
</ul>
</li>
<li>讨论Fair Diffusion的未来路径，如何融入社会促进公平</li>
</ul>
</li>
<li>意义<ul>
<li>首次为DM的公平性提供了一种实用的方法</li>
<li>用户可以重新获得对模型输出的控制权</li>
</ul>
</li>
</ul>
<h1 id="Fair-Diffusion"><a href="#Fair-Diffusion" class="headerlink" title="Fair Diffusion"></a>Fair Diffusion</h1><h2 id="公平性的定义"><a href="#公平性的定义" class="headerlink" title="公平性的定义"></a>公平性的定义</h2><ol>
<li>概括<ol>
<li>粗略地说，公平可以概括为由于某种属性而没有任何有利于一个人的倾向。</li>
<li>公平也是非常主观的Fair Diffusion的公平性定义为：数据集和模型的 算法公平性。</li>
<li>作用：公平的定义用来评价数据集和生成模型的公平性</li>
<li>存在的问题，在多个非二元属性可能相互干扰的情况下，同时满足它们变得更加具有挑战性。这种公平性定义要求所有属性都是已知的、可定义的、可测量的和可分离的</li>
</ol>
</li>
<li>具体<ol>
<li>y表示对应于x的label（firefighter），a表示一个保护的属性（gender），P是一个概率</li>
<li>要求是二进制的属性</li>
<li>用同样的概率随机选择引导的方向，形成了一个统一的概率分布，为每个属性的表达赋予相同的概率</li>
</ol>
</li>
</ol>
<h2 id="策略：在文本指导下实现公平性"><a href="#策略：在文本指导下实现公平性" class="headerlink" title="策略：在文本指导下实现公平性"></a>策略：在文本指导下实现公平性</h2><ol>
<li><p>在部署阶段指导预训练模型的公平性</p>
</li>
<li><p>Fair Diffusion可以作为指导界面实现很多操作，如用文本改变图像的生成过程</p>
</li>
<li><p>这里用SEGA做测试<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2301.12247">https://arxiv.org/abs/2301.12247</a>，可以通过文本高度灵活地编辑图像细节。比如基于检测到的偏见，将其作为指令存储在lookup table中来引导模型<br>SEGA语义引导（SEGA）允许进行细微而广泛的编辑、改变构图和风格，以及优化整体艺术构思</p>
</li>
<li><p>Fair Diffusion继承了无分类器引导<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2207.12598">https://arxiv.org/abs/2207.12598</a>，增加了一个公平引导项γ来生成图像x。这样生成器η就变成了一个关于输入prompt p和引导项γ组成的函数，其中γ通过附加的属性文本描述ei,和程度控制来获得</p>
</li>
<li><p>为了实现Fair Diffusion属性的不同表示，用期望概率分布P中随机采样来控制引导方向。也就是说属性的增加和抑制通过ei的增加和减少来控制</p>
</li>
<li><p>评价：再次用分类器对得到的属性比例验证，理想情况下，用户定义的比例和测量比例匹配<br>classifier-free guidanceSOTA：SOTA model：state-of-the-art model，并不是特指某个具体的模型，而是指在该项研究任务中，目前最好&#x2F;最先进的模型。<br>SOTA result：state-of-the-art result，指的是在该项研究任务中，目前最好的模型的结果&#x2F;性能&#x2F;表现<br>Classifier-Guidance：直接复用别人训练好的无条件扩散模型，用一个分类器来调整生成过程以实现控制生成<br>Classifier-Free：而对于“财大气粗”的Google、OpenAI等公司来说，它们不缺数据和算力，所以更倾向于往扩散模型的训练过程中就加入条件信号，达到更好的生成效果</p>
</li>
</ol>
<h2 id="具体实现方法"><a href="#具体实现方法" class="headerlink" title="具体实现方法"></a>具体实现方法</h2><h3 id="Diffusion-model-介绍"><a href="#Diffusion-model-介绍" class="headerlink" title="Diffusion model 介绍"></a>Diffusion model 介绍</h3><ol>
<li>大模型工作应用广泛，但存在偏见</li>
<li>其基本的原理：从随机噪声z开始，模型预测该噪声的估计。把输入减去估计的噪声最终得到一张图片。同时引入了step，prompt p的编码</li>
</ol>
<h3 id="公平性模型的常见方法"><a href="#公平性模型的常见方法" class="headerlink" title="公平性模型的常见方法"></a>公平性模型的常见方法</h3><ol>
<li>在学习之前对训练数据进行预处理以消除偏差</li>
<li>在训练过程中通过引入对学习目标的约束来增强公平性</li>
<li>在部署阶段[ 48、49 ]的后处理方法来修改模型结果</li>
</ol>
<h3 id="当前扩散模型存在的问题：单纯的数据预处理不能促进公平"><a href="#当前扩散模型存在的问题：单纯的数据预处理不能促进公平" class="headerlink" title="当前扩散模型存在的问题：单纯的数据预处理不能促进公平"></a>当前扩散模型存在的问题：单纯的数据预处理不能促进公平</h3><ol>
<li>对数据进行过滤依旧使模型存在偏差，同时泛化变差</li>
<li>公平的定义是主观的，不同的公平定义都需要一个专门的数据集和对应的模型，不适合大规模训练。不够泛化于下游任务</li>
<li>Schramowski等人[ 48 ]证明了在预训练过程中学习到的表征可以被利用和利用，以抑制下游任务中不需要的和不适当的行为。我们使用了类似的方法来获得公平的结果，将权力交给了个人用户。</li>
</ol>
<h3 id="具体实现：主要针对DM的-post-process-部署阶段"><a href="#具体实现：主要针对DM的-post-process-部署阶段" class="headerlink" title="具体实现：主要针对DM的(post-process)部署阶段"></a>具体实现：主要针对DM的(post-process)部署阶段</h3><ol>
<li>文本接口：即文本条件化，通过无分类器的指导实现（当前扩散模型的标准技术）</li>
<li>图像编辑方法：SEGA，因为有强大的界面来进行图像编辑。提供p和ei，通过输入z和cp到输入z，cp，ce拓展了噪声估计<ol>
<li>最初的无条件图像生成额外地受制于输入提示(无分类器指导)和用户指令(如公平引导γ)。</li>
<li>多个概念任意组合，可增加或者减少</li>
</ol>
</li>
<li>Sega以技术的方式（例如否定和条件）在句子中实现了，通过在输入提示中插入性别相关的单词来改变性别外观，确定编辑单词的正确位置是具有挑战性的，特别是如果提示中的偏见只隐式地存在</li>
</ol>
<h3 id="在扩散模型的组成部分中测量公平性"><a href="#在扩散模型的组成部分中测量公平性" class="headerlink" title="在扩散模型的组成部分中测量公平性"></a>在扩散模型的组成部分中测量公平性</h3><ol>
<li>datasets：检查数据集与目标属性（如gender）的共生性。查看是否符合公平性定义，这个比例也可以作为放大减轻偏差的参考。<ol>
<li>如何创建属性：采用能够计算文本-图像相似性的多模态模型。计算相关图像R与目标概念的文本描述p的相似性</li>
<li>通过经验确定的阈值ρ过滤来选择与描述p一致的图像，i表示数据集中的图片</li>
<li>pre-trained classifier κ（FairFace<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.04913">https://arxiv.org/abs/1908.04913</a>）来决定是否给图片标签，获得这个label，r表示图片集中的图片</li>
</ol>
</li>
<li>representation<ol>
<li>使用了image Embedding Association Test (iEAT)，可以测试表示（如encoded images）之间的关联<ol>
<li>iEAT组成：两个属性集A（职业）和B（家庭），两个目标集K（男）和L（女），如偏见模型可能会把K和A联系起来</li>
<li>计算编码目标图像与属性的差异关联，s计算编码图像w和属性a,b的关联</li>
<li>我们通过计算单侧 p 值以及效应大小 d 来评估统计显著性，σ表示标准差</li>
</ol>
</li>
</ol>
</li>
<li>Outcome：评估了stable diffusion生成的图像<ol>
<li>与数据集评测类似，创建一个合成图像数据集，计算属性相关性，从而根据定义1评估公平性</li>
<li>研究训练数据和结果之间潜在的偏见偏移，使用和搜索数据集同样的promt生成图片，也使用相同的分类器 κ来确定图像g对于保护属性的标签</li>
</ol>
</li>
</ol>
<h3 id="实验方案"><a href="#实验方案" class="headerlink" title="实验方案"></a>实验方案</h3><ol>
<li>数据：为了进行检查，我们创建了LAION-5B的新子集，其中包含超过180万张图像，显示具有可识别面孔和可识别职业的人类，并分别生成了超过37,000张具有SD和Fair Diffusion的图像。我们总共评估了超过200万张图像的性别职业偏见。</li>
<li>指令工具：<strong>SEGA</strong>，用于编辑图像并指导图像生成以获得更公平的结果</li>
<li>对属性分类：<strong>FairFace</strong>，作为κ对受保护属性进行分类，即面部（性别）属性</li>
<li>prompt设计：使用<strong>CLIP</strong>来识别LAION-5B的相关图像（描绘可识别的职业），计算图像与prompt之间的相似性（阈值0.27）。prompt模板p &#x3D; “A photo of the face of a {occ}”，该模板还用于生成带有SD的图像，此时occ ∈ {“firefighter”, “teacher”, “aide”, …}整个列表包含 150 多个不同的职业15，我们为每个职业提示生成了 250 张图像</li>
<li>公平假设：假设需要相同比例的女性和男性图像，如Def.1所示。评估受分类器限制，只能促进二进制的性别分类（当然是非二元的），但原则上可以应用与非二元</li>
<li>统计措施：计算了每组数据（二进制的男女的脸）进一步了解每个组成部分的整体性别职业偏见。因此，我们将职业列表分为f和m，其中f组表示更多偏向女性的职业，而m组则表示其他。如果LAION中女性出现的比率&gt;0.5，我们分别使用f和其他m。随后，我们评估每个组件的这些列表并生成相应的箱形图。如果没有这种组区分，平均偏差位于公平边界内（尽管箱形图显示高方差），因为两个方向都存在很强的偏差，这些偏差在总体均值计算中相互抵消。</li>
</ol>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ol>
<li>目标：调查偏见来源，使用Fair Diffusion在结果中展示缓解作用</li>
<li>模型选择：扩散模型选用Stable Diffusion 1.5，对应底层大规模数据集LAION-5B，预训练模型CLIP</li>
<li>生成使用的prompt模版：p &#x3D; “A photo of the face of a {occ}”，where occ ∈ {“firefighter”, “teacher”, “aide”, …}.</li>
<li>实验内容：男女比例</li>
<li>结果：效果对比如下，上排都是白人男性</li>
<li>结论：SD每个部分都存在偏差和不公平性</li>
</ol>
<h3 id="Stable-Diffusion中数据、模型建立不公平的现象"><a href="#Stable-Diffusion中数据、模型建立不公平的现象" class="headerlink" title="Stable Diffusion中数据、模型建立不公平的现象"></a>Stable Diffusion中数据、模型建立不公平的现象</h3><ol>
<li>在四个职业领域(science, arts, engineering, and caregiving).的子集上评估LAION-5B</li>
<li>用κ来对各职业领域的性别进行分类<ol>
<li>在艺术或护理等职业领域，女性出现的比例更高。另一方面，科学或工程的比率较低</li>
</ol>
</li>
<li>对CLIP进行偏差关联测试 3.5.b，检查不同概念的编码图像之间的相似性，结果如下<ol>
<li>男性样子的编码图像比女性样人的编码图像更接近工程相关图像，而女性形象又更接近与护理相关的图像</li>
<li>当性别职业偏见的关联测试被种族属性修改时，我们发现偏见放大。在这种情况下，男性形象由欧美人外表表示，女性形象由非裔美国人外表表示。</li>
</ol>
</li>
</ol>
<h3 id="outcome（下游任务和结果）中的偏差"><a href="#outcome（下游任务和结果）中的偏差" class="headerlink" title="outcome（下游任务和结果）中的偏差"></a>outcome（下游任务和结果）中的偏差</h3><ol>
<li>评估了从SD生成的图像，图4描绘了六个示范职业的女性出现率及其每组中位数<ol>
<li>SD生成的图像（蓝线）也包含各种职业的明显性别偏见</li>
</ol>
</li>
</ol>
<h3 id="LAION-5B和stable-diffution的结果之间是否存在偏差"><a href="#LAION-5B和stable-diffution的结果之间是否存在偏差" class="headerlink" title="LAION-5B和stable diffution的结果之间是否存在偏差"></a>LAION-5B和stable diffution的结果之间是否存在偏差</h3><ol>
<li>LAION-5B在生成的图像中的性别偏见被放大了56%，反映了22%，缓解了22%</li>
<li>进行了数据统计（了解每个组成部分的整体性别偏见）SD生成的图像和检查的LAION-5B图像的中位数（橙色线）明显超出了公平边界。这意味着LAION-5B和SD生成的图像根据定义1是不公平的。<ol>
<li>总的来说，在150种职业中，有64种更偏向于女性，而86种更偏向于男性。更重要的是，与LAION - 5B相比，( f和m)的SD生成图像的中值距离公平边界(中间)更远。</li>
<li>这种偏差的转变是由于训练数据和目标之间复杂的相互作用，以及CLIP固有的有偏表示，而这些又受到不同训练集的影响。</li>
</ol>
</li>
</ol>
<h3 id="Fair-Diffusion之后的变化"><a href="#Fair-Diffusion之后的变化" class="headerlink" title="Fair Diffusion之后的变化"></a>Fair Diffusion之后的变化</h3><ol>
<li>建立公平的fair diffusion：用FD对SD用fair guidance γ进行引导，e1-朝向女性，e2-远离男性；并以50 %的概率随机切换朝向男性出现和远离女性出现的方向，从而实现比例均分</li>
<li>缓解outcome中的偏见：箱型图中有调整后的结果。下图显示对各个职业调整后的结果</li>
<li>超越性别的趋近偏向</li>
</ol>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><ol>
<li>转移偏差范式：更公平的模型需要能够自动检测不公平性，如果预先知道可能会产生偏差的概念可以预先填写</li>
<li>模型最终是否公平：公平是不完整的，只实现了outcome的公平是不够的。要实现完全公平需要每个步骤都增加公平性。用户可以设置不均匀的概率控制输出0.4&#x2F;0.6</li>
<li>二元性别标签：本研究中性别代表性有限，缺乏超越二元性别分类的工具。提倡将性别编码为非二元</li>
<li>技术限制：LAION-5B不具有现实代表性，clip本身也有偏见，只能通过选定阈值来控制。性别分类FairFace可能也有偏见，在当前已经是最优了。使用了SEGA也要承受他的约束，即改变必须可表述</li>
<li>超越文本引导的公平性：获取编码的方式可以超越自然语言。可以通过别的多模态的方法实现</li>
<li>用户交互的挑战：恶意用户会滥用它</li>
</ol>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol>
<li>Fair Diffusion：可以生成公平的结果</li>
<li>衡量公平性：探索了 LAION-5B，并把iEAT应用于预训练表示编码器( CLIP )，发现性别和种族歧视在下游扩散模型中存在</li>
<li>文本界面控制：控制了公平性，展示了如何在任意方向上改变生成图像中的偏见，从而产生任意比例的图像。可以防止扩散模型隐式和无意地反映甚至放大偏差</li>
<li>建议：谨慎使用这些模型</li>
<li>未来工作：对组件拆解，确定偏差来源，比较不同模型的公平性也很有意思</li>
</ol>

      </div>
      
        <div class="prev-or-next">
          <div class="post-foot-next">
            
              <a href="/2024/04/21/hello-world/" target="_self">
                <i class="iconfont icon-chevronleft"></i>
                <span>Prev</span>
              </a>
            
          </div>
          <div class="post-attach">
            <span class="post-pubtime">
              <i class="iconfont icon-updatetime mr-10" title="Update time"></i>
              2024-04-21 16:33:15
            </span>
            
          </div>
          <div class="post-foot-prev">
            
              <a href="/2024/04/21/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Multimodal-datasets-misogyny-pornography-and-malignant-stereotypes/" target="_self">
                <span>Next</span>
                <i class="iconfont icon-chevronright"></i>
              </a>
            
          </div>
        </div>
      
    </div>
    
  <div id="btn-catalog" class="btn-catalog">
    <i class="iconfont icon-catalog"></i>
  </div>
  <div class="post-catalog hidden" id="catalog">
    <div class="title">Contents</div>
    <div class="catalog-content">
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-text">概述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Fair-Diffusion"><span class="toc-text">Fair Diffusion</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AC%E5%B9%B3%E6%80%A7%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-text">公平性的定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%96%E7%95%A5%EF%BC%9A%E5%9C%A8%E6%96%87%E6%9C%AC%E6%8C%87%E5%AF%BC%E4%B8%8B%E5%AE%9E%E7%8E%B0%E5%85%AC%E5%B9%B3%E6%80%A7"><span class="toc-text">策略：在文本指导下实现公平性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95"><span class="toc-text">具体实现方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Diffusion-model-%E4%BB%8B%E7%BB%8D"><span class="toc-text">Diffusion model 介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%B9%B3%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95"><span class="toc-text">公平性模型的常见方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%93%E5%89%8D%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9A%E5%8D%95%E7%BA%AF%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E4%B8%8D%E8%83%BD%E4%BF%83%E8%BF%9B%E5%85%AC%E5%B9%B3"><span class="toc-text">当前扩散模型存在的问题：单纯的数据预处理不能促进公平</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0%EF%BC%9A%E4%B8%BB%E8%A6%81%E9%92%88%E5%AF%B9DM%E7%9A%84-post-process-%E9%83%A8%E7%BD%B2%E9%98%B6%E6%AE%B5"><span class="toc-text">具体实现：主要针对DM的(post-process)部署阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86%E4%B8%AD%E6%B5%8B%E9%87%8F%E5%85%AC%E5%B9%B3%E6%80%A7"><span class="toc-text">在扩散模型的组成部分中测量公平性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%96%B9%E6%A1%88"><span class="toc-text">实验方案</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Stable-Diffusion%E4%B8%AD%E6%95%B0%E6%8D%AE%E3%80%81%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E4%B8%8D%E5%85%AC%E5%B9%B3%E7%9A%84%E7%8E%B0%E8%B1%A1"><span class="toc-text">Stable Diffusion中数据、模型建立不公平的现象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#outcome%EF%BC%88%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E5%92%8C%E7%BB%93%E6%9E%9C%EF%BC%89%E4%B8%AD%E7%9A%84%E5%81%8F%E5%B7%AE"><span class="toc-text">outcome（下游任务和结果）中的偏差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LAION-5B%E5%92%8Cstable-diffution%E7%9A%84%E7%BB%93%E6%9E%9C%E4%B9%8B%E9%97%B4%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E5%81%8F%E5%B7%AE"><span class="toc-text">LAION-5B和stable diffution的结果之间是否存在偏差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fair-Diffusion%E4%B9%8B%E5%90%8E%E7%9A%84%E5%8F%98%E5%8C%96"><span class="toc-text">Fair Diffusion之后的变化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A8%E8%AE%BA"><span class="toc-text">讨论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-text">结论</span></a></li></ol></li></ol>
      
    </div>
  </div>

  
<script src="/js/catalog.js"></script>




    
      <div class="comments-container">
        







      </div>
    
  </div>


        
<div class="footer">
  <div class="social">
    <ul>
      
        <li>
          
              <a title="github" target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">
                <i class="iconfont icon-github"></i>
              </a>
              
        </li>
        
    </ul>
  </div>
  
    
    <div class="footer-more">
      
        <a target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">Copyright © 2024 Oranges</a>
        
    </div>
  
    
    <div class="footer-more">
      
        <a target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">Theme by Oranges | Powered by Hexo</a>
        
    </div>
  
  
</div>

      </div>

      <div class="tools-bar">
        <div class="back-to-top tools-bar-item hidden">
  <a href="javascript: void(0)">
    <i class="iconfont icon-chevronup"></i>
  </a>
</div>


<script src="/js/backtotop.js"></script>



        
  <div class="search-icon tools-bar-item" id="search-icon">
    <a href="javascript: void(0)">
      <i class="iconfont icon-search"></i>
    </a>
  </div>

  <div class="search-overlay hidden">
    <div class="search-content" tabindex="0">
      <div class="search-title">
        <span class="search-icon-input">
          <a href="javascript: void(0)">
            <i class="iconfont icon-search"></i>
          </a>
        </span>
        
          <input type="text" class="search-input" id="search-input" placeholder="Search...">
        
        <span class="search-close-icon" id="search-close-icon">
          <a href="javascript: void(0)">
            <i class="iconfont icon-close"></i>
          </a>
        </span>
      </div>
      <div class="search-result" id="search-result"></div>
    </div>
  </div>

  <script type="text/javascript">
    var inputArea = document.querySelector("#search-input")
    var searchOverlayArea = document.querySelector(".search-overlay")

    inputArea.onclick = function() {
      getSearchFile()
      this.onclick = null
    }

    inputArea.onkeydown = function() {
      if(event.keyCode == 13)
        return false
    }

    function openOrHideSearchContent() {
      let isHidden = searchOverlayArea.classList.contains('hidden')
      if (isHidden) {
        searchOverlayArea.classList.remove('hidden')
        document.body.classList.add('hidden')
        // inputArea.focus()
      } else {
        searchOverlayArea.classList.add('hidden')
        document.body.classList.remove('hidden')
      }
    }

    function blurSearchContent(e) {
      if (e.target === searchOverlayArea) {
        openOrHideSearchContent()
      }
    }

    document.querySelector("#search-icon").addEventListener("click", openOrHideSearchContent, false)
    document.querySelector("#search-close-icon").addEventListener("click", openOrHideSearchContent, false)
    searchOverlayArea.addEventListener("click", blurSearchContent, false)

    var searchFunc = function (path, search_id, content_id) {
      'use strict';
      var $input = document.getElementById(search_id);
      var $resultContent = document.getElementById(content_id);
      $resultContent.innerHTML = "<ul><span class='local-search-empty'>First search, index file loading, please wait...<span></ul>";
      $.ajax({
        // 0x01. load xml file
        url: path,
        dataType: "xml",
        success: function (xmlResponse) {
          // 0x02. parse xml file
          var datas = $("entry", xmlResponse).map(function () {
            return {
              title: $("title", this).text(),
              content: $("content", this).text(),
              url: $("url", this).text()
            };
          }).get();
          $resultContent.innerHTML = "";

          $input.addEventListener('input', function () {
            // 0x03. parse query to keywords list
            var str = '<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length <= 0) {
              return;
            }
            // 0x04. perform local searching
            datas.forEach(function (data) {
              var isMatch = true;
              var content_index = [];
              if (!data.title || data.title.trim() === '') {
                data.title = "Untitled";
              }
              var orig_data_title = data.title.trim();
              var data_title = orig_data_title.toLowerCase();
              var orig_data_content = data.content.trim().replace(/<[^>]+>/g, "");
              var data_content = orig_data_content.toLowerCase();
              var data_url = data.url;
              var index_title = -1;
              var index_content = -1;
              var first_occur = -1;
              // only match artiles with not empty contents
              if (data_content !== '') {
                keywords.forEach(function (keyword, i) {
                  index_title = data_title.indexOf(keyword);
                  index_content = data_content.indexOf(keyword);

                  if (index_title < 0 && index_content < 0) {
                    isMatch = false;
                  } else {
                    if (index_content < 0) {
                      index_content = 0;
                    }
                    if (i == 0) {
                      first_occur = index_content;
                    }
                    // content_index.push({index_content:index_content, keyword_len:keyword_len});
                  }
                });
              } else {
                isMatch = false;
              }
              // 0x05. show search results
              if (isMatch) {
                str += "<li><a href='" + data_url + "' class='search-result-title'>" + orig_data_title + "</a>";
                var content = orig_data_content;
                if (first_occur >= 0) {
                  // cut out 100 characters
                  var start = first_occur - 20;
                  var end = first_occur + 80;

                  if (start < 0) {
                    start = 0;
                  }

                  if (start == 0) {
                    end = 100;
                  }

                  if (end > content.length) {
                    end = content.length;
                  }

                  var match_content = content.substr(start, end);

                  // highlight all keywords
                  keywords.forEach(function (keyword) {
                    var regS = new RegExp(keyword, "gi");
                    match_content = match_content.replace(regS, "<span class=\"search-keyword\">" + keyword + "</span>");
                  });

                  str += "<p class=\"search-result-abstract\">" + match_content + "...</p>"
                }
                str += "</li>";
              }
            });
            str += "</ul>";
            if (str.indexOf('<li>') === -1) {
              return $resultContent.innerHTML = "<ul><span class='local-search-empty'>No result<span></ul>";
            }
            $resultContent.innerHTML = str;
          });
        },
        error: function(xhr, status, error) {
          $resultContent.innerHTML = ""
          if (xhr.status === 404) {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>The search.xml file was not found, please refer to：<a href='https://github.com/zchengsite/hexo-theme-oranges#configuration' target='_black'>configuration</a><span></ul>";
          } else {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>The request failed, Try to refresh the page or try again later.<span></ul>";
          }
        }
      });
      $(document).on('click', '#search-close-icon', function() {
        $('#search-input').val('');
        $('#search-result').html('');
      });
    }

    var getSearchFile = function() {
        var path = "/search.xml";
        searchFunc(path, 'search-input', 'search-result');
    }
  </script>




        
  <div class="tools-bar-item theme-icon" id="switch-color-scheme">
    <a href="javascript: void(0)">
      <i id="theme-icon" class="iconfont icon-moon"></i>
    </a>
  </div>

  
<script src="/js/colorscheme.js"></script>





        
  
    <div class="share-icon tools-bar-item">
      <a href="javascript: void(0)" id="share-icon">
        <i class="iconfont iconshare"></i>
      </a>
      <div class="share-content hidden">
        
          <a class="share-item" href="https://twitter.com/intent/tweet?text=' + %E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Fair%20diffusion-Instructing%20Text-to-Image%20Generation%20Models%20on%20Fairness + '&url=' + http%3A%2F%2Fexample.com%2F2024%2F04%2F21%2FMy-New-Post%2F + '" target="_blank" title="Twitter">
            <i class="iconfont icon-twitter"></i>
          </a>
        
        
          <a class="share-item" href="https://www.facebook.com/sharer.php?u=http://example.com/2024/04/21/My-New-Post/" target="_blank" title="Facebook">
            <i class="iconfont icon-facebooksquare"></i>
          </a>
        
      </div>
    </div>
  
  
<script src="/js/shares.js"></script>



      </div>
    </div>
  </body>
</html>
